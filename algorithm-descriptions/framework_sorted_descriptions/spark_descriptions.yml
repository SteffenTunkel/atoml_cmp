# Field:       name 
# Description: name of the test, should be unique (duplicate name within same package+framework will lead to problems)

# Field:       type
# Description: type of the algorithm
# Supported values:
#  - classification
#  - clustering+regression planned

# Field:       framework
# Description: Machine learning framework that where the current algorithm is defined
# Supported values:
#  - weka
#  - spark
#  - sklearn

# Field:       package
# Description: package in which the algorithm is implemented

# Field:       class
# Description: name of the class that implements the algorithm

# Field:       features
# Description: defines which features can be used for the training with this algorithm, can be a list if multiple feature types are supported
# Supported values:
#  - DOUBLE          all double values (Java)
#  - FLOAT           all float values (Java)
#  - POSITIVEDOUBLE  positive double values (Java)
#  - POSITIVEFLOAT   positive float values (Java)
#  - UNIT            floating point numbers in [0,1]
#  - CATEGORICAL      categorical data

# Field:       properties
# Description: Defines which properties the algorithm should fulfill. 
# supported properties:
#  - same      re-train with the same data --> expect classes/scores to be the same
#  - scramble  re-train with randomly reordered instances --> expect classes/scores to be the same
#  - reorder   re-train with randomly reordered features --> expect classes/scores to be the same
#  - const     re-train with +1 added to all numeric features --> expect classes/scores to be the same
#  - opposite  re-train with all class labels flipped --> expect classes to be the same, scores inverted (1-priorScore)
# supported evaluations:
#  - score_exac  scores must be exactly the same after re-training
#  - class_exac  classifications must be exactly the same after re-training
#  - class_stat  classifications must not be significantly different from expectation after re-training (chi-squared test)
#  - score_stat  scores of distributionForInstance must not be significantly different from expectation after re-training (KS test)

# Field:       parameters
# Description: List of relevant hyper parameters of the algorithm.
#               Every parameter must specify a default value; the default value can be different from the default in the application
# Supported parameter types:
#  - double     double values; if min, max, and stepsize are defined these values will be tested together with the default values of all other parameters
#  - integer    integer values; if min, max, and stepsize are defined these values will be tested together with the default values of all other parameters
#  - flag       flag that is either enabled or disabled; both will be tested with the default values of the other parameters
#  - fixedflag  a flag that is always used with the default value - probably only makes sense with the value enabled.
#  - values     list of values that will be tested with the default values of the other parameters

####################
# SPARK Classifiers #
#################### 

# Functions as classifiers from the package weka.classifiers.functions


name: SPARK_LogisticRegression
framework: spark
type: classification
package:  org.apache.spark.ml.classification
class: LogisticRegression
features: [double,categorical]
properties:
  same: score_exact
  scramble: score_stat
  reorder: class_exact
  const: class_stat
  opposite: score_stat
parameters:
  setRegParam:
    type: double
    default: 0.0
  setElasticNetParam:
    type: double
    default: 0.0
  setMaxIter:
    type: integer
    default: 100
  setTol:
    type: values
    values: [0.000001]
    default: 0.000001
  setFitIntercept:
    type: values
    values: [true]
    default: true
  setFamily:
    type: values
    values: [auto]
    default: auto
  setStandardization:
    type: values
    values: [true]
    default: true
  setThreshold:
    type: values
    values: [0.5]
    default: 0.5
---


name: SPARK_MultinomialNB
framework: spark
type: classification
package:  org.apache.spark.ml.classification
class: NaiveBayes
features: [positivedouble,categorical]
properties:
  same: score_exact
  scramble: score_stat
  reorder: class_exact
  const: class_stat
  opposite: score_stat
  rotate: class_exact
  rescale: class_exact
  clone: class_exact
parameters:
  setModelType:
    type: values
    values: [multinomial]
    default: multinomial
  setSmoothing:
    type: double
    default: 1.0
---


# name: SPARK_LinearSVC
# framework: spark
# type: classification
# package:  org.apache.spark.ml.classification
# class: LinearSVC
# features: [double,categorical]
# properties:
#   same: score_exact
#   scramble: score_stat
#   reorder: class_exact
#   const: class_stat
#   opposite: score_stat
#   rotate: class_exact
#   rescale: class_exact
#   clone: class_exact
# parameters:
#   setRegParam:
#     type: double
#     default: 1.0
#   setMaxIter:
#     type: integer
#     default: 1000
#   setFitIntercept:
#     type: values
#     values: [false]
#     default: false
#   setTol:
#     type: values
#     values: [0.000001]
#     default: 0.000001
#   setStandardization:
#     type: values
#     values: [false]
#     default: false
#   setThreshold:
#     type: double
#     default: 0.5
# ---

# name: SPARK_LinearSVC
# framework: spark
# type: classification
# package:  org.apache.spark.ml.classification
# class: LinearSVC
# features: [double,categorical]
# properties:
#   same: score_exact
#   scramble: score_stat
#   reorder: class_exact
#   const: class_stat
#   opposite: score_stat
#   rotate: class_exact
#   rescale: class_exact
#   clone: class_exact
# parameters:
#   setRegParam:
#     type: double
#     default: 0.0
#   setMaxIter:
#     type: integer
#     default: 100
#   setFitIntercept:
#     type: values
#     values: [false]
#     default: false
#   setTol:
#     type: values
#     values: [0.000001]
#     default: 0.000001
#   setStandardization:
#     type: values
#     values: [true]
#     default: true
#   setThreshold:
#     type: double
#     default: 0.5
# ---


# name: SPARK_NaiveBayes_Bernoulli
# framework: spark
# type: classification
# package:  org.apache.spark.ml.classification
# class: NaiveBayes
# features: categorical
# properties:
#   same: score_exact
#   scramble: score_stat
#   reorder: class_exact
#   const: class_stat
#   opposite: score_stat
#   rotate: class_exact
#   rescale: class_exact
#   clone: class_exact
# parameters:
#   setModelType:
#     type: values
#     values: [bernoulli]
#     default: bernoulli
#   setSmoothing:
#     type: double
#     default: 0.0
# ---

name: SPARK_MLPgd
framework: spark
type: classification
package:  org.apache.spark.ml.classification
class: MultilayerPerceptronClassifier
features: [double,categorical]
properties:
  same: score_exact
  scramble: score_stat
  reorder: class_exact
  const: class_stat
  opposite: score_stat
  rotate: class_exact
  rescale: class_exact
  clone: class_exact
parameters:
  setSolver:
    type: values
    values: [gd] #[gd, l-bfgs]
    default: gd
  setStepSize:
    type: double
    default: 0.2
  setMaxIter:
    type: integer
    default: 1000
  setTol:
    type: values
    values: [0.0001]
    default: 0.0001
  setLayers:
    type: values
    values: ["10,10,2"]
    default: "10,10,2"
  setBlockSize:
    type: integer
    default: 200
---


name: SPARK_MLPlbfgs
framework: spark
type: classification
package:  org.apache.spark.ml.classification
class: MultilayerPerceptronClassifier
features: [double,categorical]
properties:
  same: score_exact
  scramble: score_stat
  reorder: class_exact
  const: class_stat
  opposite: score_stat
  rotate: class_exact
  rescale: class_exact
  clone: class_exact
parameters:
  setSolver:
    type: values
    values: [l-bfgs] #[gd, l-bfgs]
    default: l-bfgs
  setStepSize:
    type: double
    default: 0.002
  setMaxIter:
    type: integer
    default: 10000
  setTol:
    type: values
    values: [0.0001]
    default: 0.0001
  setLayers:
    type: values
    values: ["10,10,2"]
    default: "10,10,2"
---




# name: SPARK_RandomForestClassifier
# framework: spark
# type: classification
# package:  org.apache.spark.ml.classification
# class: RandomForestClassifier
# features: [double,categorical]
# properties:
#   same: score_exact
#   scramble: score_stat
#   reorder: class_exact
#   const: class_stat
#   opposite: score_stat
#   rotate: class_exact
#   rescale: class_exact
#   clone: class_exact
# parameters:
#   setMaxDepth:
#     type: integer
#     default: 3
#   setMinInfoGain:
#     type: double
#     default: 0.0
#   setMaxBins:
#     type: integer
#     default: 32
#   setMinInstancesPerNode:
#     type: integer
#     default: 1
#   setImpurity:
#     type: values
#     values: [gini] #[gini, entropy]
#     default: gini
#   setNumTrees:
#     type: integer
#     default: 20
#   setSubsamplingRate:
#     type: double
#     default: 1.0
#   setFeatureSubsetStrategy:
#     type: values
#     values: [sqrt] #[auto, all, sqrt, onethird, log2, 0.5, 2]
#     default: sqrt
# ---