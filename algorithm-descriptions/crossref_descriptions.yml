# Field:       name 
# Description: name of the test, should be unique (duplicate name within same package+framework will lead to problems)

# Field:       type
# Description: type of the algorithm
# Supported values:
#  - classification
#  - clustering+regression planned

# Field:       framework
# Description: Machine learning framework that where the current algorithm is defined
# Supported values:
#  - weka
#  - spark
#  - sklearn

# Field:       package
# Description: package in which the algorithm is implemented

# Field:       class
# Description: name of the class that implements the algorithm

# Field:       features
# Description: defines which features can be used for the training with this algorithm, can be a list if multiple feature types are supported
# Supported values:
#  - DOUBLE          all double values (Java)
#  - FLOAT           all float values (Java)
#  - POSITIVEDOUBLE  positive double values (Java)
#  - POSITIVEFLOAT   positive float values (Java)
#  - UNIT            floating point numbers in [0,1]
#  - CATEGORICAL      categorical data

# Field:       properties
# Description: Defines which properties the algorithm should fulfill. 
# supported properties:
#  - same      re-train with the same data --> expect classes/scores to be the same
#  - scramble  re-train with randomly reordered instances --> expect classes/scores to be the same
#  - reorder   re-train with randomly reordered features --> expect classes/scores to be the same
#  - const     re-train with +1 added to all numeric features --> expect classes/scores to be the same
#  - opposite  re-train with all class labels flipped --> expect classes to be the same, scores inverted (1-priorScore)
# supported evaluations:
#  - score_exac  scores must be exactly the same after re-training
#  - class_exac  classifications must be exactly the same after re-training
#  - class_stat  classifications must not be significantly different from expectation after re-training (chi-squared test)
#  - score_stat  scores of distributionForInstance must not be significantly different from expectation after re-training (KS test)

# Field:       parameters
# Description: List of relevant hyper parameters of the algorithm.
#               Every parameter must specify a default value; the default value can be different from the default in the application
# Supported parameter types:
#  - double     double values; if min, max, and stepsize are defined these values will be tested together with the default values of all other parameters
#  - integer    integer values; if min, max, and stepsize are defined these values will be tested together with the default values of all other parameters
#  - flag       flag that is either enabled or disabled; both will be tested with the default values of the other parameters
#  - fixedflag  a flag that is always used with the default value - probably only makes sense with the value enabled.
#  - values     list of values that will be tested with the default values of the other parameters

####################
# Weka Classifiers #
#################### 

# Functions as classifiers from the package weka.classifiers.functions

name: WEKA_LOGISTIC
type: classification
framework: weka
package: weka.classifiers.functions
class: Logistic
features: [double,categorical]
properties:
  same: score_exact
  scramble: score_exact
  reorder: score_exact
  const: score_exact
  opposite: score_exact
parameters:
  R: # ridge value of the log likelihood
    # actually a double, but values give better tests
    type: values
    values: [1.0E-7, 1.0E-8, 1.0E-9]
    stepsize: 0.9E-8
    default: 1.0E-8
  C: # use conjugate gradiant descent
    type: flag
    default: disabled
---

name: WEKA_SimpleLogistic
type: classification
framework: weka
package: weka.classifiers.functions
class: SimpleLogistic
features: [double,categorical]
properties:
  same: score_exact
  scramble: score_exact
  reorder: score_exact
  const: score_exact
  opposite: score_exact
parameters:
  P: # error on probabilities
    type: flag
    default: disabled
  H: # heuristic stoping criterion
    type: integer
    min: 0
    max: 100
    stepsize: 50
    default: 50
  M: # maximum of boosting iterations (actually, zero is allowed - is this a bug?)
    type: integer
    min: 1
    max: 999
    stepsize: 499
    default: 500
  I: # sets a fixed number of boosting iterations
    type: integer
    min: 0
    max: 1000
    stepsize: 500
    default: 0
  A: # use AIC to determine number of boosting iterations
    type: flag
    default: disabled
  S: # whether cross-validation is used for determining the number of boosting iterations
    type: flag
    default: disabled
  W: # beta value for weight trimming of boosting
    type: double
    min: 0.0
    max: 0.9
    stepsize: 0.45
    default: 0.0
---

#################################
# Scikit-Learn 0.22 Classifiers #
#################################

name: SKLEARN_GaussianNB
framework: sklearn
type: classification
package:  sklearn.naive_bayes
class: GaussianNB
features: double
properties:
  same: score_exact
  scramble: score_exact
  reorder: score_exact
  const: score_exact
  opposite: score_exact
parameters:
  var_smoothing:
    type: values
    values: [0.000000001, 0.0000001]
    default: 0.000000001
#  priors: missing because arrays are not yet supported
---

name: SKLEARN_SGDClassifier
framework: sklearn
type: classification
package:  sklearn.linear_model
class: SGDClassifier
features: double
properties:
  same: score_exact
  scramble: score_exact
  reorder: score_exact
  const: score_exact
  opposite: score_exact
parameters:
  loss:
    type: values
    values: [hinge, log, modified_huber, squared_hinge, perceptron]
    default: hinge
  penalty:
    type: values
    values: [l2, l1, elasticnet]
    default: l2
  alpha:
    type: values
    values: [0.00001, 0.0001, 0.001]
    default: 0.0001
  l1_ratio:
    type: double
    min: 0.0
    max: 1.0
    stepsize: 0.5
    default: 0.15
  max_iter:
    type: integer
    min: 1
    max: 1999
    stepsize: 999
    default: 1000
  tol:
    type: values
    values: [0.001]
    default: 0.001
  shuffle:
    type: values
    values: [True, False]
    default: True
  learning_rate:
    type: values
    values: [constant, optimal, invscaling, adaptive]
    default: optimal
  eta0:
    type: double
    min: 0.0
    max: 0.1
    stepsize: 0.05
    default: 0.0
  power_t:
    type: double
    min: 0.1
    max: 0.9
    stepsize: 0.4
    default: 0.5
  early_stopping:
    type: values
    values: [True, False]
    default: False
  validation_fraction:
    type: double
    min: 0.1
    max: 0.9
    stepsize: 0.4
    default: 0.1
  n_iter_no_change:
    type: integer
    min: 1
    max: 9
    stepsize: 4
    default: 5
  class_weight:
    type: values
    values: [balanced, None]
    default: None
  average:
    type: values
    values: [True, False, 10]
    default: False
---
    
name: SKLEARN_BernoulliNB
framework: sklearn
type: classification
package:  sklearn.naive_bayes
class: BernoulliNB
features: double
properties:
  same: score_exact
  scramble: score_exact
  reorder: score_exact
  const: score_exact
  opposite: score_exact
parameters:
  alpha:
    type: double
    min: 0.0
    max: 1.5
    stepsize: 0.5
    default: 1.0
  binarize:
    type: double
    min: 0.0
    max: 1.5
    stepsize: 0.5
    default: 0.0
  fit_prior:
    type: values
    values: [True, False]
    default: True
#  class_prior: missing because arrays are not yet supported
---

name: SKLEARN_CategoricalNB
framework: sklearn
type: classification
package:  sklearn.naive_bayes
class: CategoricalNB
features: categorical
properties:
  same: score_exact
  scramble: score_exact
  reorder: score_exact
  const: score_exact
  opposite: score_exact
parameters:
  alpha:
    type: double
    min: 0.0
    max: 1.5
    stepsize: 0.5
    default: 1.0
  fit_prior: # somehow not supported?!
    type: values
    values: [True, False]
    default: True
#  class_prior: missing because arrays are not yet supported
---

################## SPARK ###########################
    
name: SPARK_LogisticRegression
framework: spark
type: classification
package:  org.apache.spark.ml.classification
class: LogisticRegression
features: [double,categorical]
properties:
  same: score_exact
  scramble: score_stat
  reorder: class_exact
  const: class_stat
  opposite: score_stat
parameters:
  setRegParam:
    type: double
    min: 0.0
    max: 1.0
    stepsize: 0.5
    default: 0.0
  setElasticNetParam:
    type: double
    min: 0.0
    max: 1.0
    stepsize: 0.5
    default: 0.0
  setMaxIter:
    type: integer
    min: 1
    max: 999
    stepsize: 499
    default: 100
  setTol:
    type: values
    values: [0.000001, 0.00001, 0.0000001]
    default: 0.000001
  setFitIntercept:
    type: values
    values: [true, false]
    default: true
  setFamily:
    type: values
    values: [auto, binomial, multinomial]
    default: auto
  setStandardization:
    type: values
    values: [true, false]
    default: true
  setThreshold:
    type: double
    min: 0.0
    max: 1.0
    stepsize: 0.5
    default: 0.5
---
