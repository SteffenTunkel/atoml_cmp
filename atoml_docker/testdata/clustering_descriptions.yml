# Field:       name
# Description: name of the test, should be unique (duplicate name within same package+framework will lead to problems)

# Field:       type
# Description: type of the algorithm
# Supported values:
#  - classification
#  - clustering+regression planned

# Field:       framework
# Description: Machine learning framework that where the current algorithm is defined
# Supported values:
#  - weka
#  - spark
#  - sklearn

# Field:       package
# Description: package in which the algorithm is implemented

# Field:       class
# Description: name of the class that implements the algorithm

# Field:       features
# Description: defines which features can be used for the training with this algorithm, can be a list if multiple feature types are supported
# Supported values:
#  - DOUBLE          all double values (Java)
#  - FLOAT           all float values (Java)
#  - POSITIVEDOUBLE  positive double values (Java)
#  - POSITIVEFLOAT   positive float values (Java)
#  - UNIT            floating point numbers in [0,1]
#  - CATEGORICAL      categorical data

# Field:       properties
# Description: Defines which properties the algorithm should fulfill.
# supported properties:
#  - same      re-train with the same data --> expect classes/scores to be the same
#  - scramble  re-train with randomly reordered instances --> expect classes/scores to be the same
#  - reorder   re-train with randomly reordered features --> expect classes/scores to be the same
#  - const     re-train with +1 added to all numeric features --> expect classes/scores to be the same
#  - opposite  re-train with all class labels flipped --> expect classes to be the same, scores inverted (1-priorScore)
# supported evaluations:
#  - score_exact scores must be exactly the same after re-training
#  - class_exact classifications must be exactly the same after re-training
#  - class_stat  classifications must not be significantly different from expectation after re-training (chi-squared test)
#  - score_stat  scores of distributionForInstance must not be significantly different from expectation after re-training (KS test)
#  - clust_exact clusters must be exactly the same after re-training
#  - clust_stat  clusters must not be significantly different from expectation after re-training

# Field:       parameters
# Description: List of relevant hyper parameters of the algorithm.
#               Every parameter must specify a default value; the default value can be different from the default in the application
# Supported parameter types:
#  - double     double values; if min, max, and stepsize are defined these values will be tested together with the default values of all other parameters
#  - integer    integer values; if min, max, and stepsize are defined these values will be tested together with the default values of all other parameters
#  - flag       flag that is either enabled or disabled; both will be tested with the default values of the other parameters
#  - fixedflag  a flag that is always used with the default value - probably only makes sense with the value enabled.
#  - values     list of values that will be tested with the default values of the other parameters

####################
# Weka Clustering Algorithms #
####################

# clusterers from the package weka.clusterers

name: WEKA_CANOPY
type: clustering
framework: weka
package: weka.clusterers
class: Canopy
features: [double,categorical]
properties:
  same: clust_stat
  scramble: clust_stat
  reorder: clust_stat
  const: clust_stat
parameters:
  N: # number of clusters
    type: integer
    min: 2
    max: 4
    stepsize: 1
    default: 2
  max-candidates: # maximum number of candidates to remain in memory during training
    type: integer
    min: 100
    max: 300
    stepsize: 100
    default: 100
  periodic-pruning: # how often to prune low density canopies during training
    type: integer
    min: 200
    max: 500
    stepsize: 100
    default: 300
  min-density: # minimum T2-based density below which canopy is pruned during periodic pruning
    type: double
    min: 2.0
    max: 6.0
    stepsize: 1.0
    default: 2.0
  t2: # T2 distance
    type: double
    min: 1.0
    max: 3.0
    stepsize: 1.0
    default: -1.0
  t1: # T1 distance
    type: double
    min: 0.5
    max: 2.5
    stepsize: 1.0
    default: -1.25
  M: # do not replace missing values with means
    type: flag
    default: disabled
  S: # random number seed to be used
    type: integer
    min: 0
    max: 42
    stepsize: 21
    default: 42
  output-debug-info: # true: clusterer outputs additional information to console
    type: flag
    default: disabled
  do-not-check-capabilities: # true: clusterer capabilities are not checked before building clusterer (to reduce runtime)
    type: flag
    default: disabled
---

name: WEKA_COBWEB
type: clustering
framework: weka
package: weka.clusterers
class: Cobweb
features: [double,categorical]
properties:
  same: clust_stat
  scramble: clust_stat
  reorder: clust_stat
  const: clust_stat
parameters:
  A: # minimum standard deviation for numeric attributes
    type: double
    min: 0.5
    max: 2.0
    stepsize: 0.5
    default: 1.0
  C: # category utility threshold by which to prune nodes
    type: double
    min: 0.001
    max: 0.011
    stepsize: 0.005
    default: 0.0028
  save-data: # save instances information for visualization purpose
    type: flag
    default: disabled
  S: # random number seed to be used
    type: integer
    min: 0
    max: 42
    stepsize: 21
    default: 42
  output-debug-info: # true: clusterer outputs additional information to console
    type: flag
    default: disabled
  do-not-check-capabilities: # true: clusterer capabilities are not checked before building clusterer (to reduce runtime)
    type: flag
    default: disabled
---

name: WEKA_EM
type: clustering
framework: weka
package: weka.clusterers
class: EM
features: [double,categorical]
properties:
  same: clust_stat
  scramble: clust_stat
  reorder: clust_stat
  const: clust_stat
parameters:
  I: # max number of iterations
    type: integer
    min: 100
    max: 200
    stepsize: 100
    default: 100
  N: # number of clusters
    type: integer
    min: 2
    max: 4
    stepsize: 1
    default: 2
  X: # number of folds to use when cross-validating to find best number of clusters
    type: integer
    min: 8
    max: 12
    stepsize: 1
    default: 10
  max: # maximum number of clusters to consider during cross-validating
    type: integer
    min: 2
    max: 5
    stepsize: 1
    default: 2
  ll-cv: # minimum improvement in cross-validated log likelihood required to consider increasing number of clusters during cross-validation
    type: double
    min: 1.0E-6
    max: 1.0E-5
    stepsize: 3.0E-6
    default: 1.0E-6
  ll-iter: # minimum improvement in log likelihood required to perform another iteration of E and M steps
    type: double
    min: 1.0E-6
    max: 1.0E-5
    stepsize: 3.0E-6
    default: 1.0E-6
  M: # minimum allowable standard deviation
    type: double
    min: 1.0E-6
    max: 1.0E-5
    stepsize: 3.0E-6
    default: 1.0E-6
  K: # number of kMeans runs to perform
    type: integer
    min: 5
    max: 15
    stepsize: 10
    default: 10
  O: # model output in old format
    type: flag
    default: disabled
  num-slots: # number of execution slots (threads) to use
    type: integer
    min: 1
    max: 4
    stepsize: 1
    default: 1
  S: # random number seed to be used
    type: integer
    min: 0
    max: 42
    stepsize: 21
    default: 42
  output-debug-info: # true: clusterer outputs additional information to console
    type: flag
    default: disabled
  do-not-check-capabilities: # true: clusterer capabilities are not checked before building clusterer (to reduce runtime)
    type: flag
    default: disabled
---

name: WEKA_FARTHESTFIRST
type: clustering
framework: weka
package: weka.clusterers
class: FarthestFirst
features: [double,categorical]
properties:
  same: clust_stat
  scramble: clust_stat
  reorder: clust_stat
  const: clust_stat
parameters:
  N: # number of clusters
    type: integer
    min: 2
    max: 3
    stepsize: 1
    default: 2
  S: # random number seed to be used
    type: integer
    min: 0
    max: 50
    stepsize: 10
    default: 1
  output-debug-info: # true: clusterer outputs additional information to console
    type: flag
    default: disabled
  do-not-check-capabilities: # true: clusterer capabilities are not checked before building clusterer (to reduce runtime)
    type: flag
    default: disabled
---

name: WEKA_HIERARCHICALCLUSTERER
type: clustering
framework: weka
package: weka.clusterers
class: HierarchicalClusterer
features: [double,categorical]
properties:
  same: clust_stat
  scramble: clust_stat
  reorder: clust_stat
  const: clust_stat
parameters:
  N: # number of clusters
    type: integer
    min: 2
    max: 3
    stepsize: 1
    default: 2
  L: # method used to measure distance between two clusters
    type: values
    values: [SINGLE, COMPLETE, AVERAGE, MEAN, CENTROID, WARD, ADJCOMPLETE, NEIGHBOR_JOINING]
    default: SINGLE
  P: # indicates if cluster should be printed in Newick format
    type: flag
    default: enabled
  B: # if false, distance between clusters is interpreted as height of the node linking the clusters
    type: flag
    default: disabled
  A: # distance function
    type: values
    values: ["weka.core.EuclideanDistance -R first-last", "weka.core.ChebyshevDistance -R first-last",
             "weka.core.FilteredDistance -R first-last -F \\\\\"weka.filters.unsupervised.attribute.RandomProjection -N 10 -R 42 -D Sparse1\\\\\" -D \\\\\"weka.core.EuclideanDistance -R first-last\\\\\"",
             "weka.core.ManhattanDistance -R first-last", "weka.core.MinkowskiDistance -P 2.0 -R first-last"]
    default: "weka.core.EuclideanDistance -R first-last"
  output-debug-info: # true: clusterer outputs additional information to console
    type: flag
    default: disabled
  do-not-check-capabilities: # true: clusterer capabilities are not checked before building clusterer (to reduce runtime)
    type: flag
    default: disabled
---

name: WEKA_SIMPLEKMEANS
type: clustering
framework: weka
package: weka.clusterers
class: SimpleKMeans
features: [double,categorical]
properties:
  same: clust_stat
  scramble: clust_stat
  reorder: clust_stat
  const: clust_stat
parameters:
  init: # initialization method to use
    type: integer
    min: 0
    max: 3
    stepsize: 1
    default: 0
  C: # use canopy clustering to reduce comparisons during kMeans algorithm
    type: flag
    default: enabled
  max-candidates: # if canopy clustering: maximum number of candidates to remain in memory during training of canopy clusterer
    type: integer
    min: 100
    max: 300
    stepsize: 100
    default: 100
  periodic-pruning: # if canopy clustering: how often to prune low density canopies during training
    type: integer
    min: 100
    max: 1000
    stepsize: 500
    default: 1000
  min-density: # if canopy clustering: minimum T2-based density below which canopy is pruned during periodic pruning
    type: double
    min: 0.0
    max: 8.0
    stepsize: 2.0
    default: 2.0
  t1: # if canopy clustering: T1 distance
    type: double
    min: -1.25
    max: 2.25
    #    stepsize: 1.0
    default: -1.25
  t2: # if canopy clustering: T2 distance
    type: double
    min: -1.0
    max: 2.0
    #    stepsize: 1.0
    default: -1.0
  V: # display standard deviations
    type: flag
    default: disabled
  M: # do not replace missing values with means
    type: flag
    default: disabled
  N: # number of clusters
    type: integer
    min: 2
    max: 4
    stepsize: 1
    default: 2
  A: # distance function to use for instances comparison
    type: values
    values: ["weka.core.EuclideanDistance -R first-last", "weka.core.ManhattanDistance -R first-last"]
    default: "weka.core.EuclideanDistance -R first-last"
  I: # maximum number of iterations
    type: integer
    min: 300
    max: 700
    stepsize: 100
    default: 500
  O: # preserve order of instances
    type: flag
    default: disabled
  fast: # use cutoff values for speeding up distance calculation
    type: flag
    default: disabled
  num-slots: # number of execution slots (threads) to use
    type: integer
    min: 1
    max: 2
    stepsize: 1
    default: 1
  S: # random number seed to be used
    type: integer
    min: 0
    max: 42
    stepsize: 21
    default: 42
  output-debug-info: # true: clusterer outputs additional information to console
    type: flag
    default: disabled
  do-not-check-capabilities: # true: clusterer capabilities are not checked before building clusterer (to reduce runtime)
    type: flag
    default: disabled
---


#################################
# Scikit-Learn 0.22 Clusterers #
#################################

name: SKLEARN_AffinityPropagation
framework: sklearn
type: clustering
package:  sklearn.cluster
class: AffinityPropagation
features: [double,categorical]
properties:
  same: clust_stat
  scramble: clust_stat
  reorder: clust_stat
  const: clust_stat
parameters:
  damping: # extent to which current value is maintained relative to incoming values (weighted 1 - damping)
    type: double
    min: 0.5
    max: 0.9
    stepsize: 0.2
    default: 0.5
  max_iter: # maximum number of iterations
    type: integer
    min: 50
    max: 150
    stepsize: 50
    default: 100
  convergence_iter: # number of iterations with no change in number of estimated clusters that stops the convergence
    type: integer
    min: 10
    max: 20
    stepsize: 5
    default: 15
  copy: # make copy of input data
    type: values
    values: [True, False]
    default: True
  random_state: # random number generator to control starting state
    type: integer
    min: 0
    max: 42
    stepsize: 21
    default: 0
  verbose: # be verbose or not
    type: values
    values: [True, False]
    default: False
---

name: SKLEARN_AgglomerativeClusteringWardNClusters # Ward only works with default parameters therefore not much specified here
framework: sklearn
type: clustering
package:  sklearn.cluster
class: AgglomerativeClustering
features: [double,categorical]
properties:
  same: clust_stat
  scramble: clust_stat
  reorder: clust_stat
  const: clust_stat
parameters:
  n_clusters: # number of clusters to find
    type: values
    values: [2, 3, 4]
    default: 2
  compute_full_tree: # early stop of construction of tree to decrease computation time
    type: values
    values: [auto, True, False]
    default: auto
---

name: SKLEARN_AgglomerativeClusteringWardDistThresh # Ward only works with default parameters therefore not much specified here
framework: sklearn
type: clustering
package:  sklearn.cluster
class: AgglomerativeClustering
features: [double,categorical]
properties:
  same: clust_stat
  scramble: clust_stat
  reorder: clust_stat
  const: clust_stat
parameters:
  n_clusters: # number of clusters to find
    type: values
    values: [None, None]
    default: None
  distance_threshold: # linkage distance threshold above which clusters will not be merged
    type: values
    values: [0.3, 1.0, 2.0, 5.0]
    default: 2.0
---

name: SKLEARN_AgglomerativeClusteringNoWardNClusters
framework: sklearn
type: clustering
package:  sklearn.cluster
class: AgglomerativeClustering
features: [double,categorical]
properties:
  same: clust_stat
  scramble: clust_stat
  reorder: clust_stat
  const: clust_stat
parameters:
  n_clusters: # number of clusters to find
    type: values
    values: [2, 3, 4]
    default: 2
  affinity: # metric used to compute linkage
    type: values
    values: [euclidean, l1, l2, manhattan, cosine]
    default: euclidean
  compute_full_tree: # early stop of construction of tree to decrease computation time
    type: values
    values: [auto, True, False]
    default: auto
  linkage: # which linkage criterion to use
    type: values
    values: [complete, average, single]
    default: average
---

name: SKLEARN_AgglomerativeClusteringNoWardDistThresh
framework: sklearn
type: clustering
package:  sklearn.cluster
class: AgglomerativeClustering
features: [double,categorical]
properties:
  same: clust_stat
  scramble: clust_stat
  reorder: clust_stat
  const: clust_stat
parameters:
  n_clusters: # number of clusters to find
    type: values
    values: [None, None]
    default: None
  affinity: # metric used to compute linkage
    type: values
    values: [euclidean, l1, l2, manhattan, cosine]
    default: euclidean
  linkage: # which linkage criterion to use
    type: values
    values: [complete, average, single]
    default: average
  distance_threshold: # linkage distance threshold above which clusters will not be merged
    type: values
    values: [0.3, 1.0, 2.0, 5.0]
    default: 2.0
---

name: SKLEARN_Birch
framework: sklearn
type: clustering
package:  sklearn.cluster
class: Birch
features: [double,categorical]
properties:
  same: clust_stat
  scramble: clust_stat
  reorder: clust_stat
  const: clust_stat
parameters:
  threshold: # radius of subcluster obtained by merging a new sample and the closest subcluster should be lesser than the threshold
    type: double
    min: 0.5
    max: 1.0
    stepsize: 0.5
    default: 0.5
  branching_factor: # maximum number of CF subclusters in each node
    type: integer
    min: 10
    max: 110
    stepsize: 50
    default: 50
  n_clusters: # number of clusters at the final clustering step
    type: integer
    min: 2
    max: 4
    stepsize: 1
    default: 2
  copy: # whether or not to make a copy of the given data, if false initial data is overwritten
    type: values
    values: [True, False]
    default: True
---

name: SKLEARN_DBSCAN
framework: sklearn
type: clustering
package:  sklearn.cluster
class: DBSCAN
features: [double,categorical]
properties:
  same: clust_stat
  scramble: clust_stat
  reorder: clust_stat
  const: clust_stat
parameters:
  eps: # maximum distance between two samples for one to be considered as in the neighborhood of the other
    type: double
    min: 0.2
    max: 0.8
    stepsize: 0.1
    default: 0.5
  min_samples: # number of samples in a neighborhood for a point to be considered a core point
    type: integer
    min: 3
    max: 10
    stepsize: 1
    default: 5
  metric: # metric to use when calculating distance between instances in a feature array
    type: values
    values: [cityblock, cosine, euclidean, l1, l2, manhattan] # only used sklearn's metrics, also scipy.spatial.distance possible
    default: euclidean
  algorithm: # algorithm to be used by NearestNeighbors module to compute pointwise distances and find nearest neighbors
    type: values
    values: [auto, ball_tree, kd_tree, brute]
    default: auto
  leaf_size: # leaf size passed to BallTree or cKDTree
    type: integer
    min: 10
    max: 100
    stepsize: 30
    default: 50
  p: # power of the Minkowski metric used for distance calculation between points
    type: values
    values: [0.2, 0.5, 0.8, 1.1, 1.5, None]
    default: None
  n_jobs: # number of parallel jobs to run, None meaning 1, -1 meaning all processors
    type: values
    values: [-1, 2, None]
    default: None
---

name: SKLEARN_KMeans
framework: sklearn
type: clustering
package:  sklearn.cluster
class: KMeans
features: [double,categorical]
properties:
  same: clust_stat
  scramble: clust_stat
  reorder: clust_stat
  const: clust_stat
parameters:
  n_clusters: # number of clusters to find
    type: integer
    min: 2
    max: 4
    stepsize: 1
    default: 2
  init: # initialization method
    type: values
    values: [k-means++, random]
    default: k-means++
  n_init: # number of times k-means algorithm will be run with different centroid seeds
    type: integer
    min: 5
    max: 10
    stepsize: 5
    default: 10
  max_iter: # maximum number of iterations for single run of k-means
    type: integer
    min: 100
    max: 500
    stepsize: 100
    default: 300
  tol: # relative tolerance with regards to inertia to declare convergence
    type: values
    values: [0.000001, 0.00001, 0.0001, 0.001, 0.01]
    default: 0.0001
  verbose: # be verbose or not
    type: values
    values: [0, 1]
    default: 0
  random_state: # determines random number generation for centroid initialization
    type: values
    values: [0, 21, 42, None]
    default: 0
  copy_x: # if True, original data is not modified ensuring X is C-contiguous
    type: values
    values: [True, False]
    default: True
  algorithm: # which k-means algorithm to use
    type: values
    values: [auto, full, elkan]
    default: auto
---

name: SKLEARN_MiniBatchKMeans
framework: sklearn
type: clustering
package:  sklearn.cluster
class: MiniBatchKMeans
features: [double,categorical]
properties:
  same: clust_stat
  scramble: clust_stat
  reorder: clust_stat
  const: clust_stat
parameters:
  n_clusters: # number of clusters to find
    type: integer
    min: 2
    max: 4
    stepsize: 1
    default: 2
  init: # initialization method
    type: values
    values: [k-means++, random]
    default: k-means++
  max_iter: # maximum number of iterations for single run of k-means
    type: integer
    min: 100
    max: 300
    stepsize: 100
    default: 100
  batch_size: # size of mini batches
    type: integer
    min: 50
    max: 250
    stepsize: 50
    default: 100
  verbose: # be verbose or not
    type: values
    values: [0, 1]
    default: 0
  random_state: # determines random number generation for centroid initialization
    type: values
    values: [0, 21, 42, None]
    default: None
  tol: # controls early stopping based on relative center changes
    type: values
    values: [0.0, 0.00001, 0.001]
    default: 0.0
  max_no_improvement: # controls early stopping based on consecutive number of mini batches not yielding improvements on smoothed inertia
    type: integer
    min: 5
    max: 20
    stepsize: 5
    default: 10
  init_size: # number of samples to randomly sample for speeding up the initialization, None equals 3 * batch_size
    type: values
    values: [100, 300, 500, None]
    default: None
  n_init: # number random initializations that are tried
    type: integer
    min: 1
    max: 7
    stepsize: 2
    default: 3
  reassignment_ratio: # controls fraction of maximum number of counts for a center to be reassigned
    type: values
    values: [0.001, 0.005, 0.01, 0.05, 0.1]
    default: 0.01
---

name: SKLEARN_MeanShift
framework: sklearn
type: clustering
package:  sklearn.cluster
class: MeanShift
features: [double,categorical]
properties:
  same: clust_stat
  scramble: clust_stat
  reorder: clust_stat
  const: clust_stat
parameters:
  bin_seeding: # if True initial kernel locations are not locations of all points but location of discretized version of points
    type: values
    values: [True, False]
    default: False
  cluster_all: # if True, all points are clustered, also those not in a kernel
    type: values
    values: [True, False]
    default: True
  n_jobs: # number of jobs to use for computation, None equals 1, -1 equals all processors
    type: values
    values: [-1, 2, None]
    default: None
  max_iter: # maximum number of iterations per seed point before clustering operation terminates
    type: integer
    min: 100
    max: 300
    stepsize: 100
    default: 150
---

name: SKLEARN_OPTICS
framework: sklearn
type: clustering
package:  sklearn.cluster
class: OPTICS
features: [double,categorical]
properties:
  same: clust_stat
  scramble: clust_stat
  reorder: clust_stat
  const: clust_stat
parameters:
  min_samples: # number of samples in a neighborhood for a point to be considered as core point
    type: values
    values: [3, 5, 10]
    default: 5
  max_eps: # maximum distance between two samples for one to be considered as in the neighborhood of the other, optional
    type: values
    values: [1.0, 2.0, 5.0, 10.0]
    default: 5.0
  metric: # metric used for distance computation, only sklearn's metrices used
    type: values
    values: [cityblock, cosine, euclidean, l1, l2, manhattan, minkowski]
    default: minkowski
  p: # parameter for minkowski metric form
    type: integer
    min: 1
    max: 4
    stepsize: 1
    default: 2
  cluster_method: # extraction method for extracting clusters using calculated reachability and ordering
    type: values
    values: [dbscan, xi]
    default: xi
  eps: # maximum distance between two samples for one to be considered as in the neighborhood of the other
    type: values
    values: [None, 2.0, 5.0]
    default: None
  xi: # determines minimum steepness on the reachability plot that constitues a cluster boundary
    type: values
    values: [0.01, 0.03, 0.05, 0.1, 0.5]
    default: 0.05
  predecessor_correction: # correct clusters according to the predecessors calculated by OPTICS
    type: values
    values: [True, False]
    default: True
  min_cluster_size: # minimum number of samples in an OPTICS cluster
    type: values
    values: [2, 5, 10, None]
    default: None
  algorithm: # algorithm used to compute nearest neighbors
    type: values
    values: [auto, ball_tree, kd_tree, brute]
    default: auto
  leaf_size: # leaf size passed to BallTree or KDTree
    type: integer
    min: 10
    max: 70
    stepsize: 30
    default: 50
  n_jobs: # number of parallel jobs to run for neighbors search, None equals 1, -1 equals all processors
    type: values
    values: [-1, 2, None]
    default: None
---

name: SKLEARN_SpectralClusteringNClusters
framework: sklearn
type: clustering
package:  sklearn.cluster
class: SpectralClustering
features: [double,categorical]
properties:
  same: clust_stat
  scramble: clust_stat
  reorder: clust_stat
  const: clust_stat
parameters:
  n_clusters: # dimension of project subspace, optional
    type: values
    values: [2, 3, 4]
    default: 2
  eigen_solver: # eigenvalue decomposition strategy to use
    type: values
    values: [arpack, lobpcg, None] # amg option currently not supported
    default: lobpcg
  n_components: # number of eigen vectors to use for spectral embedding
    type: values
    values: [2, 4]
    default: 2
  random_state: # pseudo random number generator for initializing of lobpcg eigen vector decomposition
    type: values
    values: [0, 42, None]
    default: 42
  n_init: # number of times the k-means algorithm will be run with different centroid seeds
    type: values
    values: [5, 10, 15]
    default: 10
  gamma: # kernel coefficient for rbf, poly sigmoid, laplacian and chi2 kernels
    type: double
    min: 1.0
    max: 2.0
    stepsize: 1.0
    default: 1.0
  affinity: # how to construct affinity matrix
    type: values
    values: [nearest_neighbors, rbf]
    default: rbf
  n_neighbors: # number of neighbors to use when constructing affinity matrix with nearest neighbors
    type: integer
    min: 5
    max: 10
    stepsize: 1
    default: 7
  eigen_tol: # stopping criterion for eigendecomposition of laplacian matrix
    type: values
    values: [0.0, 0.5, 1.0]
    default: 0.0
  assign_labels: # strategy to assign labels in the embedding space
    type: values
    values: [kmeans, discretize]
    default: kmeans
  degree: # degree of polynomial kernel
    type: double
    min: 1.0
    max: 5.0
    stepsize: 2.0
    default: 3.0
  coef0: # zero coefficient for polynomial and sigmoid kernels
    type: double
    min: 0.5
    max: 2.0
    stepsize: 0.5
    default: 1.0
  n_jobs: # number of parallel jobs to run for neighbors search, None equals 1, -1 equals all processors
    type: values
    values: [-1, 2, None]
    default: None
---

name: SKLEARN_SpectralClusteringNoNClusters
framework: sklearn
type: clustering
package:  sklearn.cluster
class: SpectralClustering
features: [double,categorical]
properties:
  same: clust_stat
  scramble: clust_stat
  reorder: clust_stat
  const: clust_stat
parameters:
  n_components: # number of eigen vectors to use for spectral embedding
    type: values
    values: [2, 4]
    default: 2
  eigen_solver: # eigenvalue decomposition strategy to use
    type: values
    values: [arpack, lobpcg, None] # amg option currently not supported
    default: lobpcg
  random_state: # pseudo random number generator for initializing of lobpcg eigen vector decomposition
    type: values
    values: [0, 42, None]
    default: 42
  n_init: # number of times the k-means algorithm will be run with different centroid seeds
    type: values
    values: [5, 10, 15]
    default: 10
  gamma: # kernel coefficient for rbf, poly sigmoid, laplacian and chi2 kernels
    type: double
    min: 1.0
    max: 2.0
    stepsize: 1.0
    default: 1.0
  affinity: # how to construct affinity matrix
    type: values
    values: [nearest_neighbors, rbf]
    default: rbf
  n_neighbors: # number of neighbors to use when constructing affinity matrix with nearest neighbors
    type: integer
    min: 5
    max: 10
    stepsize: 1
    default: 7
  eigen_tol: # stopping criterion for eigendecomposition of laplacian matrix
    type: values
    values: [0.0, 0.5, 1.0]
    default: 0.0
  assign_labels: # strategy to assign labels in the embedding space
    type: values
    values: [kmeans, discretize]
    default: kmeans
  degree: # degree of polynomial kernel
    type: double
    min: 1.0
    max: 5.0
    stepsize: 2.0
    default: 3.0
  coef0: # zero coefficient for polynomial and sigmoid kernels
    type: double
    min: 0.5
    max: 2.0
    stepsize: 0.5
    default: 1.0
  n_jobs: # number of parallel jobs to run for neighbors search, None equals 1, -1 equals all processors
    type: values
    values: [-1, 2, None]
    default: None
---

name: SKLEARN_GaussianMixture
framework: sklearn
type: clustering
package:  sklearn.mixture
class: GaussianMixture
features: [double,categorical]
properties:
  same: clust_stat
  scramble: clust_stat
  reorder: clust_stat
  const: clust_stat
parameters:
  n_components: # number of mixture components in the model
    type: integer
    min: 2
    max: 4
    stepsize: 1
    default: 2
  covariance_type: # type of covariance parameters to use
    type: values
    values: [full, tied, diag, spherical]
    default: full
  tol: # convergence threshold
    type: double
    min: 0.001
    max: 0.01
    stepsize: 0.003
    default: 0.001
  reg_covar: # regularization added to diagonal of covariance to assure they are all positive
    type: double
    min: 0.00001
    max: 0.00009
    stepsize: 0.00004
    default: 0.00005
  max_iter: # maximum number of EM iterations to perform
    type: integer
    min: 50
    max: 200
    stepsize: 50
    default: 100
  n_init: # number of initializations to perform
    type: integer
    min: 1
    max: 10
    stepsize: 3
    default: 1
  init_params: # initialization method to use
    type: values
    values: [kmeans, random]
    default: kmeans
  warm_start: # use solution of last fitting as initialization for next call of fit()
    type: values
    values: [True, False]
    default: False
  verbose: # enable verbose output
    type: integer
    min: 0
    max: 1
    stepsize: 1
    default: 0
---

####################
# Apache Spark Clustering Algorithms #
####################

name: SPARK_KMEANS
framework: spark
type: clustering
package:  org.apache.spark.ml.clustering
class: KMeans
features: [double,categorical]
properties:
  same: clust_stat
  scramble: clust_stat
  reorder: clust_stat
  const: clust_stat
parameters:
  k: # number of desired clusters
    type: integer
    min: 2
    max: 4
    stepsize: 1
    default: 2
  maxIter: # maximum number of iterations to run
    type: integer
    min: 0
    max: 100
    stepsize: 50
    default: 50
  initMode: # either random or k-means initialization
    type: values
    values: [random, k-means||]
    default: k-means||
  initSteps: # number of steps in the k-means|| algorithm
    type: integer
    min: 1
    max: 3
    stepsize: 1
    default: 2
  tol: # distance threshold determining whether k-means has converged
    type: double
    min: 0.0
    max: 2.1
    stepsize: 0.7
    default: 0.5
  distanceMeasure: # distance measure to use
    type: values
    values: [euclidean, cosine]
    default: euclidean
---

name: SPARK_GAUSSIAN # Gaussian Mixture Model Clustering
framework: spark
type: clustering
package:  org.apache.spark.ml.clustering
class: GaussianMixture
features: [double,categorical]
properties:
  same: clust_stat
  scramble: clust_stat
  reorder: clust_stat
  const: clust_stat
parameters:
  k: # number of desired clusters
    type: integer
    min: 2
    max: 4
    stepsize: 1
    default: 2
  maxIter: # maximum number of iterations to run
    type: integer
    min: 0
    max: 100
    stepsize: 50
    default: 50
  tol: # maximum change in log-likelihood at which convergence is considered to be achieved
    type: double
    min: 0.1
    max: 0.5
    stepsize: 0.1
    default: 0.2
---

#name: SPARK_PIC # Power Iteration Clustering (PIC) not fully support since in experimental mode in Spark
#framework: spark
#type: clustering
#package:  org.apache.spark.ml.clustering
#class: PowerIterationClustering
#features: double
#properties:
#  same: clust_exact
#  scramble: clust_stat
#  opposite: clust_exact
#parameters:
#  k: # number of desired clusters
#    type: integer
#    min: 2
#    max: 4
#    stepsize: 1
#    default: 2
#  maxIter: # maximum number of iterations to run
#    type: integer
#    min: 0
#    max: 150
#    stepsize: 50
#    default: 50
#---

name: SPARK_BISECTING_KMEANS
framework: spark
type: clustering
package:  org.apache.spark.ml.clustering
class: BisectingKMeans
features: [double,categorical]
properties:
  same: clust_stat
  scramble: clust_stat
  reorder: clust_stat
  const: clust_stat
parameters:
  k: # number of desired clusters
    type: integer
    min: 2
    max: 4
    stepsize: 1
    default: 2
  maxIter: # maximum number of iterations to run
    type: integer
    min: 0
    max: 100
    stepsize: 50
    default: 50
  minDivisibleClusterSize: # the minimum number (if >= 1.0) or minimum proportion of points (if < 1.0) of a divisible cluster
    type: double
    min: 0.5
    max: 1.5
    stepsize: 1.0
    default: 1.0
---
